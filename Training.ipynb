{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "63m_7eC2keu7",
        "outputId": "d2e36214-18cc-4d1b-c56b-bc45a969b5c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t1m9592k0r2",
        "outputId": "7197b3ad-5571-442f-a6bc-bb19214033cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd drive/'My Drive'/personal_projects/ta-lib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/personal_projects/ta-lib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsoMD02hHHqp",
        "outputId": "65f9b58a-dc88-4b37-bea6-e46aa51cc6f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nproc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZqpFivmk6Zn",
        "outputId": "c4887979-d336-4831-dbeb-ade69e360146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install ta-lib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libta-lib0.\n",
            "(Reading database ... 144617 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) ...\n",
            "Selecting previously unselected package ta-lib0-dev.\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting ta-lib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/cf/681911aa31e04ba171ab4d523a412f4a746e30d3eacb1738799d181e028b/TA-Lib-0.4.19.tar.gz (267kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta-lib) (1.18.5)\n",
            "Building wheels for collected packages: ta-lib\n",
            "  Building wheel for ta-lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta-lib: filename=TA_Lib-0.4.19-cp36-cp36m-linux_x86_64.whl size=1437800 sha256=709aba75699c73bcf444d7d3cefaf7ea70141f40782ea9e7999cdb4aca001216\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/f6/12/3d1ccd06caadd8fa47e016991dd0d27f1163bb260f1854e2ff\n",
            "Successfully built ta-lib\n",
            "Installing collected packages: ta-lib\n",
            "Successfully installed ta-lib-0.4.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZx3p_Yuk-yh",
        "outputId": "12efc454-e271-4af1-a663-97efa750062d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/personal_projects\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP_BjnsmMRvP"
      },
      "source": [
        "# !mkdir checkpoints"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKzI8hbccjTW",
        "outputId": "89b53e12-7af3-4d46-9b2c-530197f0ebe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls -l"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 142851\n",
            "-rw------- 1 root root    35723 Oct  6 18:26 allowed_index\n",
            "drwx------ 2 root root     4096 Sep 25 04:04 \u001b[0m\u001b[01;34mAXISBANK\u001b[0m/\n",
            "-rw------- 1 root root 19855254 Aug 16 07:34 AXISBANK__EQ__NSE__NSE__MINUTE.csv\n",
            "drwx------ 2 root root     4096 Sep 25 04:03 \u001b[01;34mBAJFINANCE\u001b[0m/\n",
            "-rw------- 1 root root 20819583 Aug 16 07:34 BAJFINANCE__EQ__NSE__NSE__MINUTE.csv\n",
            "-rw------- 1 root root   219552 Oct  9 17:46 base_best_model.h5\n",
            "drwx------ 2 root root     4096 Oct  9 17:39 \u001b[01;34mcheckpoints\u001b[0m/\n",
            "drwx------ 2 root root     4096 Sep 25 04:05 \u001b[01;34mHDFC\u001b[0m/\n",
            "drwx------ 2 root root     4096 Sep 25 04:05 \u001b[01;34mHDFCBANK\u001b[0m/\n",
            "-rw------- 1 root root 20397667 Aug 16 07:34 HDFCBANK__EQ__NSE__NSE__MINUTE.csv\n",
            "-rw------- 1 root root 21026418 Aug 16 07:34 HDFC__EQ__NSE__NSE__MINUTE.csv\n",
            "drwx------ 2 root root     4096 Sep 25 04:06 \u001b[01;34mICICIBANK\u001b[0m/\n",
            "-rw------- 1 root root 20078776 Aug 16 07:34 ICICIBANK__EQ__NSE__NSE__MINUTE.csv\n",
            "-rw------- 1 root root 21067770 Aug 16 07:34 NIFTY_50__EQ__INDICES__NSE__MINUTE.csv\n",
            "-rw------- 1 root root 21417156 Aug 16 07:34 NIFTY_BANK__EQ__INDICES__NSE__MINUTE.csv\n",
            "drwx------ 5 root root     4096 Sep 15  2007 \u001b[01;34mta-lib\u001b[0m/\n",
            "-rw------- 1 root root  1330299 Sep 15  2007 ta-lib-0.4.0-src.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_sEsbuW7Wgb",
        "outputId": "ca4721b6-f82f-48e0-a356-74df5182fd9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Oct 10 12:56:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   75C    P0    35W /  70W |    869MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97r9YzRyf2cg"
      },
      "source": [
        "# common imports\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from talib import NATR, RSI"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17GQES1HW1uz"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense, Masking, Concatenate, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.layers.core import Activation, Dropout, Reshape\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# from hyperas import optim\n",
        "# from hyperas.distributions import choice, uniform\n",
        "# from hyperopt import Trials, STATUS_OK, tpe\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZrw3vRZiozd"
      },
      "source": [
        "# model_interface.py\n",
        "\n",
        "# This is an abstract class. You need to implement yours.\n",
        "class AbstractModelBuilder(object):\n",
        "\n",
        "  def __init__(self, weights_path = None):\n",
        "    self.weights_path = weights_path\n",
        "    self.model = None\n",
        "\n",
        "  def loadModel(self):\n",
        "    weights_path = self.weights_path\n",
        "    self.model = self.buildModel()\n",
        "\n",
        "    if weights_path and os.path.isfile(weights_path):\n",
        "      try:\n",
        "        self.model.load_weights(weights_path)\n",
        "      except e:\n",
        "        print(e)\n",
        "\n",
        "  # You need to override this method.\n",
        "  def buildModel(self):\n",
        "    raise NotImplementedError(\"You need to implement your own model.\")\n",
        "\n",
        "  def predict(self, data):\n",
        "    raise NotImplementedError(\"You need to implement predictor function\")\n",
        "\n",
        "  def compile_model(self):\n",
        "    raise NotImplementedError(\"You need to implement this function\")\n",
        "\n",
        "  def trainModel(self, inputs, targets):\n",
        "    raise NotImplementedError(\"You need to implement this function\")\n",
        "  \n",
        "  def printSummary(self):\n",
        "    raise NotImplementedError(\"You need to implement this function\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxfFAS0EigJi"
      },
      "source": [
        "\n",
        "# do a cut off\n",
        "# unable to build (PnL transfer t to t+1)?\n",
        "# Doesn't work\n",
        "# class lstm_model(AbstractModelBuilder):\n",
        "  \n",
        "#   def buildModel(self):\n",
        "#       inputs = []\n",
        "    \n",
        "#       weekly_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "#       inputs.append(weekly_inputs)\n",
        "    \n",
        "#       encoder_inputs = Dense(8, activation='relu')(weekly_inputs)\n",
        "#       week_encoder = LSTM(16, return_state=True)\n",
        "#       encoder_outputs, state_h, state_c = week_encoder(encoder_inputs)\n",
        "#       encoder_states = [state_h, state_c]\n",
        "\n",
        "#       input_price_info = Input(shape=(None, 3))\n",
        "#       inputs.append(input_price_info)\n",
        "#       inputs_rsi_macd_schaff = Input(shape=(None, 4))\n",
        "#       inputs.append(inputs_rsi_macd_schaff)\n",
        "#       input_bolinger = Input(shape=(None, 3))\n",
        "#       inputs.append(input_bolinger)\n",
        "#       input_adx = Input(shape(None, 3))\n",
        "#       inputs.append(input_adx)\n",
        "#       input_one_hot = Input(shape(None, 8))\n",
        "#       inputs.append(input_one_hot)\n",
        "\n",
        "#       x1 = Dense(6, activation='leaky relu')(input_price_info)\n",
        "#       x2 = Dense(6, activation='leaky relu')(input_adx)\n",
        "#       x3 = Dense(6, activation='leaky relu')(input_bolinger)\n",
        "#       x4 = Dense(8, activation='leaky relu')(input_one_hot)\n",
        "\n",
        "#       feature_vector = Concatenate(axis=1)(x1, inputs_rsi_macd_schaff, x2, x3, x4)\n",
        "#       x = Dense(64, activation='relu')(feature_vector)\n",
        "#       embedding = Dropout(0.5)(x)\n",
        "\n",
        "#       layer_1 = LSTM(64, return_sequences=True)\n",
        "#       x = layer_1(embedding, initial_state=encoder_states)\n",
        "#       output_layer_1 = Activation('leaky relu')(x)\n",
        "\n",
        "#       layer_2 = LSTM(32, return_sequences=True)\n",
        "#       x = layer_2(output_layer_1)\n",
        "#       output_layer_2 = Activation('leaky relu')(x)\n",
        "\n",
        "#       final_dense = Dense(3, activation='linear')\n",
        "#       final_output = final_dense(output_layer_2)\n",
        "\n",
        "#       model = Model(inputs, final_output)\n",
        "#       return model\n",
        "\n",
        "# Take past 30 timesteps one hot veectors then use cnn and give it to the neural net \n",
        "\n",
        "\n",
        "class cnn_model(AbstractModelBuilder):\n",
        "\n",
        "  def buildModel(self):\n",
        "    hourly_data = Input(shape=(1, 30, 3))\n",
        "\n",
        "    x = Conv2D(2, (1,3), activation='relu')(hourly_data)\n",
        "    x = MaxPooling2D(pool_size=(1,2))(x)\n",
        "    x = Conv2D(4, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2))(x)\n",
        "    x = Conv2D(4, (1,3), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x0 = Dense(8, activation='relu')(x)\n",
        "\n",
        "    input_PnL = Input(shape=(11,))\n",
        "    x1 = Dense(6)(input_PnL)\n",
        "    x1 = LeakyReLU()(x1)\n",
        "\n",
        "    # scaling\n",
        "    input_scale = Input(shape=(30,))\n",
        "    x = Dense(4, activation='relu')(input_scale)\n",
        "    x_scale = Dense(1)(x)\n",
        "\n",
        "    inputs = [hourly_data, input_PnL, input_scale]\n",
        "    input_price_info = Input(shape=(1, 60, 2))\n",
        "    inputs.append(input_price_info)\n",
        "    input_indicators = Input(shape=(1, 60, 5))\n",
        "    inputs.append(input_indicators)\n",
        "    input_bolinger = Input(shape=(4, 60, 1))\n",
        "    inputs.append(input_bolinger)\n",
        "    input_adx = Input(shape=(1, 60, 3))\n",
        "    inputs.append(input_adx)\n",
        "    input_nb = Input(shape=(1, 30, 2))\n",
        "    inputs.append(input_nb)\n",
        "    input_onehot = Input(shape=(10, 30, 1))\n",
        "    inputs.append(input_onehot)\n",
        "\n",
        "    # price\n",
        "    x = Conv2D(5, (1,3), activation='relu')(input_price_info)\n",
        "    x = Conv2D(8, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(12, (1,3), activation='relu')(x)\n",
        "    x = Conv2D(14, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(16, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(25, activation='relu')(x)\n",
        "    x_price = Dropout(0.3)(x)\n",
        "\n",
        "    # nifty bank\n",
        "    x = Conv2D(3, (1,3), activation='relu')(input_nb)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(4, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(5, (1,3), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x_nb = Dense(6)(x)\n",
        "\n",
        "    # adx\n",
        "    x = Dense(1)(input_adx)\n",
        "    x = LeakyReLU()(x)\n",
        "    indicators = Concatenate(axis=3)([input_indicators, x, input_adx[:,:,:,1:]])\n",
        "\n",
        "    # bolinger\n",
        "    x = Conv2D(3, (4,3), activation='relu')(input_bolinger)\n",
        "    x = Conv2D(4, (1,5), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(5, (1,7), activation='relu')(x)\n",
        "    x = Conv2D(6, (1,10), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10, activation='relu')(x)\n",
        "    x_bolinger = Dropout(0.3)(x)\n",
        "\n",
        "    # onehot\n",
        "    x = Conv2D(8, (8,3), activation='relu')(input_onehot)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(10, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(12, (1,5), activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10, 'relu')(x)\n",
        "    x_onehot = Dropout(0.2)(x)\n",
        "\n",
        "    #indicators\n",
        "    x = Conv2D(8, (1,3), activation='relu')(indicators)\n",
        "    x = Conv2D(12, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x) \n",
        "    x = Conv2D(12, (1,3), activation='relu')(x)\n",
        "    x = Conv2D(16, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Conv2D(20, (1,3), activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(1,2), strides=(1,2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(20, activation='relu')(x)\n",
        "    x_indicators = Dropout(0.3)(x)\n",
        "\n",
        "    # concatenate and combine all the feature_vectors\n",
        "    x = Concatenate(axis=1)([x_price, x_bolinger, x_indicators, x_onehot, x_nb])\n",
        "    x = Dense(30)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # concatenate context\n",
        "    x = Concatenate(axis=1)([x, x1, x0])\n",
        "    x = Dense(23)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Dense(12)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "\n",
        "    # Experiment with tanh too\n",
        "    x = Dense(3, activation='linear')(x)\n",
        "\n",
        "    # doesn't bloody work\n",
        "    # provide scaling\n",
        "    # possible to force x_scale > 0 ? \n",
        "    # May try BatchNormalization in price and nb\n",
        "    final_output = x * tf.math.abs(x_scale)\n",
        "\n",
        "    # num trainable params large ~ 20k ? \n",
        "    model = Model(inputs, final_output)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "  def compile_model(self):\n",
        "    self.model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "  def predict(self, data, sub_sample=None):\n",
        "    if sub_sample is None:\n",
        "      return self.model.predict([data['hourly_data'],   \n",
        "                      data['portfolio'],\n",
        "                      data['scale'], \n",
        "                      data['price_curve'],\n",
        "                      data['indicators'],\n",
        "                      data['bolinger'],\n",
        "                      data['adx'],\n",
        "                      data['nb'],\n",
        "                      data['onehot']])\n",
        "    else:\n",
        "      return self.model.predict([data['hourly_data'][sub_sample],   \n",
        "                      data['portfolio'][sub_sample],\n",
        "                      data['scale'][sub_sample], \n",
        "                      data['price_curve'][sub_sample],\n",
        "                      data['indicators'][sub_sample],\n",
        "                      data['bolinger'][sub_sample],\n",
        "                      data['adx'][sub_sample],\n",
        "                      data['nb'][sub_sample],\n",
        "                      data['onehot'][sub_sample]])\n",
        "\n",
        "\n",
        "  def batchTrain(self, data, targets):\n",
        "    return self.model.train_on_batch([data['hourly_data'],    \n",
        "                      data['portfolio'],\n",
        "                      data['scale'], \n",
        "                      data['price_curve'],\n",
        "                      data['indicators'],\n",
        "                      data['bolinger'],\n",
        "                      data['adx'],\n",
        "                      data['nb'],\n",
        "                      data['onehot']],\n",
        "                      targets)\n",
        "  \n",
        "  def fitModel(self, data, targets, batch_size, epoch):\n",
        "    return self.model.fit([data['hourly_data'],    \n",
        "                      data['portfolio'],\n",
        "                      data['scale'], \n",
        "                      data['price_curve'],\n",
        "                      data['indicators'],\n",
        "                      data['bolinger'],\n",
        "                      data['adx'],\n",
        "                      data['nb'],\n",
        "                      data['onehot']],\n",
        "                      targets,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epoch)\n",
        "  \n",
        "  def printSummary(self):\n",
        "    print(self.model.summary())"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxPFqMFmP9yO"
      },
      "source": [
        "# Improvements\n",
        "# prioritized Experience Replay\n",
        "# Dual Target Network\n",
        "# Better Optimzation techique\n",
        "class ExperienceReplay(object):\n",
        "  \n",
        "  def __init__(self, max_memory=250000, discount=.9):\n",
        "    self.max_memory = max_memory\n",
        "    self.count_range = {}\n",
        "    self.memory = list()\n",
        "    self.discount = discount\n",
        "    self.record_sort = False\n",
        "\n",
        "  def remember(self, states, game_over):\n",
        "    for i in range(p_games):\n",
        "      save_states_tm1, save_states_t = {}, {}\n",
        "      for key in states[0].keys():\n",
        "        save_states_tm1[key] = states[0][key][i]\n",
        "        save_states_t[key] = states[3][key][i]\n",
        "      self.memory.append([[save_states_tm1, int(states[1][i]), states[2][i][0], save_states_t], 1.0 - float(game_over), 0])\n",
        "    if self.record_sort:\n",
        "      if self.count_range.__contains__(0):\n",
        "        l, r = self.count_range[0]\n",
        "        self.count_range[0] = (l, r + len(states[0]))\n",
        "      else:\n",
        "        self.count_range[0] = (len(self.memory) - 1, len(self.memory) - 1 + len(states[0]))\n",
        "    \n",
        "    if len(self.memory) > self.max_memory:\n",
        "      del self.memory[:30000]\n",
        "\n",
        "  # keep record sorted\n",
        "  def _adjust_record(self, idx):\n",
        "    if not self.record_sort:\n",
        "      return\n",
        "\n",
        "    old_count = self.memory[idx][2]\n",
        "    self.memory[idx][2] = old_count + 1\n",
        "    old_l,old_r = self.count_range[old_count]\n",
        "  \n",
        "    if idx != old_l:\n",
        "      temp = self.memory[idx]\n",
        "      self.memory[idx] = self.memory[old_l]\n",
        "      self.memory[old_l] = temp\n",
        "\n",
        "    if self.count_range.__contains__(old_count + 1):\n",
        "      new_l,new_r = self.count_range[old_count + 1]\n",
        "      self.count_range[old_count + 1] = (new_l, new_r + 1)\n",
        "    else:\n",
        "      self.count_range[old_count + 1] = (old_l, old_l)\n",
        "\n",
        "    if old_l + 1 > old_r:\n",
        "      del self.count_range[old_count - 1]\n",
        "    else:\n",
        "      self.count_range[old_count - 1] = (old_l + 1, old_r)\n",
        "\n",
        "  # use it for fast speed (uses a lot more memory)\n",
        "  def get_offline_batch(self, env, model_interface, batch_size):\n",
        "    len_memory = len(self.memory)\n",
        "    size = min(len_memory, batch_size)\n",
        "    num_actions = model_interface.model.output_shape[-1]\n",
        "    inputs = {}\n",
        "    inputs_t = {}\n",
        "    reward = np.empty(size)\n",
        "    over = np.empty(size)\n",
        "    action = np.zeros((size, num_actions), dtype=bool)\n",
        "    price_curve, indicators, bolinger, adx, nb, onehot, portfolio, hourly_data, scale_data = self.allocate(size)\n",
        "    price_curve_t, indicators_t, bolinger_t, adx_t, nb_t, onehot_t, portfolio_t, hourly_data_t, scale_data_t = self.allocate(size)\n",
        "\n",
        "    for i, idx in enumerate(np.random.randint(0, len_memory, size=size)):\n",
        "      state_t, action_t, reward_t, state_tp1 = self.memory[idx][0]\n",
        "      \n",
        "      price_curve[i] = state_t['price_curve']\n",
        "      indicators[i] = state_t['indicators']\n",
        "      bolinger[i] = state_t['bolinger']\n",
        "      adx[i] = state_t['adx']\n",
        "      onehot[i] = state_t['onehot']\n",
        "      nb[i] = state_t['nb']\n",
        "      portfolio[i] = state_t['portfolio']\n",
        "      hourly_data[i] = state_t['hourly_data']\n",
        "      scale_data[i] = state_t['scale']\n",
        "      \n",
        "      price_curve_t[i] = state_tp1['price_curve']\n",
        "      indicators_t[i] = state_tp1['indicators']\n",
        "      bolinger_t[i] = state_tp1['bolinger']\n",
        "      adx_t[i] = state_tp1['adx']\n",
        "      onehot_t[i] = state_tp1['onehot']\n",
        "      nb_t[i] = state_tp1['nb']\n",
        "      portfolio_t[i] = state_tp1['portfolio']\n",
        "      hourly_data_t[i] = state_tp1['hourly_data']\n",
        "      scale_data_t[i] = state_tp1['scale']\n",
        "\n",
        "      reward[i] = reward_t\n",
        "      action[i][action_t] = True\n",
        "      over[i] = self.memory[idx][1]\n",
        "    \n",
        "    inputs['price_curve'] = price_curve\n",
        "    inputs['indicators'] = indicators\n",
        "    inputs['bolinger'] = bolinger\n",
        "    inputs['adx'] = adx\n",
        "    inputs['onehot'] = onehot\n",
        "    inputs['portfolio'] = portfolio\n",
        "    inputs['nb'] = nb\n",
        "    inputs['scale'] = scale_data\n",
        "    inputs['hourly_data'] = hourly_data\n",
        "\n",
        "    inputs_t['price_curve'] = price_curve_t\n",
        "    inputs_t['indicators'] = indicators_t\n",
        "    inputs_t['bolinger'] = bolinger_t\n",
        "    inputs_t['adx'] = adx_t\n",
        "    inputs_t['onehot'] = onehot_t\n",
        "    inputs_t['portfolio'] = portfolio_t\n",
        "    inputs_t['nb'] = nb_t\n",
        "    inputs_t['scale'] = scale_data_t\n",
        "    inputs_t['hourly_data'] = hourly_data_t\n",
        "\n",
        "    targets = model_interface.predict(inputs)\n",
        "    targets[action] = reward + self.discount * over * np.max(model_interface.predict(inputs_t), axis=1)\n",
        "\n",
        "    return inputs, targets\n",
        "\n",
        "  def allocate(self, size):\n",
        "    p_s = list(self.memory[0][0][0]['price_curve'].shape)\n",
        "    i_s = list(self.memory[0][0][0]['indicators'].shape)\n",
        "    b_s = list(self.memory[0][0][0]['bolinger'].shape)\n",
        "    a_s = list(self.memory[0][0][0]['adx'].shape)\n",
        "    o_s = list(self.memory[0][0][0]['onehot'].shape)\n",
        "    pf_s = list(self.memory[0][0][0]['portfolio'].shape)\n",
        "    n_s = list(self.memory[0][0][0]['nb'].shape)\n",
        "    s_s = list(self.memory[0][0][0]['scale'].shape)\n",
        "    h_s = list(self.memory[0][0][0]['hourly_data'].shape) \n",
        "\n",
        "    return np.empty([size] + p_s), np.empty([size] + i_s), np.empty([size] + b_s), np.empty([size] + a_s), np.empty([size] + n_s), np.empty([size] + o_s), np.empty([size] + pf_s), np.empty([size] + h_s), np.empty([size] + s_s)\n",
        "\n",
        "  # used for low memory usage\n",
        "  def get_online_batch(self, env, model_interface, batch_size=64):\n",
        "    len_memory = len(self.memory)\n",
        "    num_actions = model_interface.model.output_shape[-1]\n",
        "    inputs = {}\n",
        "    price_curve, indicators, bolinger, adx, nb, onehot, portfolio, hourly_data, scale_data = [], [], [], [], [], [], [], [], []\n",
        "\n",
        "    targets = np.zeros((min(len_memory, batch_size), num_actions))\n",
        "    for i, idx in enumerate(np.random.randint(0, len_memory, size=min(len_memory, batch_size))):\n",
        "      pnl_state_t, action_t, reward_t, pnl_state_tp1, code, day, index = self.memory[idx][0]\n",
        "      self._adjust_record(idx)\n",
        "      state_t = env.generate_data(code, day, index)\n",
        "      state_t['portfolio'] = pnl_state_t\n",
        "      game_over = self.memory[idx][1]\n",
        "      targets[i] = model_interface.predict(state_t)[0]\n",
        "      if not game_over:\n",
        "        state_tp1 = env.generate_data(code, day, index + 1)\n",
        "        state_tp1['portfolio'] = pnl_state_tp1\n",
        "        Q_sa = np.max(model_interface.predict(state_tp1)[0])\n",
        "        targets[i, action_t] = reward_t + self.discount * Q_sa\n",
        "      else:\n",
        "        targets[i, action_t] = reward_t\n",
        "\n",
        "      price_curve.append(np.squeeze(state_t['price_curve'], axis=0))\n",
        "      indicators.append(np.squeeze(state_t['indicators'], axis=0))\n",
        "      bolinger.append(np.squeeze(state_t['bolinger'], axis=0))\n",
        "      adx.append(np.squeeze(state_t['adx'], axis=0))\n",
        "      onehot.append(np.squeeze(state_t['onehot'], axis=0))\n",
        "      nb.append(np.squeeze(state_t['nb'], axis=0))\n",
        "      portfolio.append(np.squeeze(state_t['portfolio'], axis=0))\n",
        "      hourly_data.append(np.squeeze(state_t['hourly_data'], axis=0))\n",
        "      scale_data.append(np.squeeze(state_t['scale'], axis=0))\n",
        "\n",
        "\n",
        "    inputs['price_curve'] = np.array(price_curve)\n",
        "    inputs['indicators'] = np.array(indicators)\n",
        "    inputs['bolinger'] = np.array(bolinger)\n",
        "    inputs['adx'] = np.array(adx)\n",
        "    inputs['onehot'] = np.array(onehot)\n",
        "    inputs['portfolio'] = np.array(portfolio)\n",
        "    inputs['nb'] = np.array(nb)\n",
        "    inputs['scale'] = np.array(scale_data)\n",
        "    inputs['hourly_data'] = np.array(hourly_data)\n",
        "\n",
        "    return inputs, targets"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2YbXipbUeJD"
      },
      "source": [
        "path_list = ['BAJFINANCE/processed_data', 'AXISBANK/processed_data', 'HDFC/processed_data', 'HDFCBANK/processed_data', 'ICICIBANK/processed_data']\n",
        "X_price_info, X_indicators, X_adx, X_bolinger, X_onehot, X_nb = [{} for _ in range(6)]\n",
        "X_avg_val, X_high_val, X_low_val, X_close_val = [{} for _ in range(4)]\n",
        "\n",
        "code = 0\n",
        "for path in path_list:\n",
        "  if not os.path.exists(path):\n",
        "    print('path not found', path)\n",
        "  else:\n",
        "    f = open(path, 'rb')\n",
        "    obj = pickle.load(f)\n",
        "    X_price_info[code] = obj['X_price_info']\n",
        "    X_indicators[code] = obj['X_indicators']\n",
        "    X_adx[code] = obj['X_adx']\n",
        "    X_bolinger[code] = obj['X_bolinger']\n",
        "    X_onehot[code] = obj['X_onehot']\n",
        "    X_nb[code] = obj['X_nb']\n",
        "    X_avg_val[code] = obj['avg_val']\n",
        "    X_high_val[code] = obj['high_val']\n",
        "    X_low_val[code] = obj['low_val']\n",
        "    X_close_val[code] = obj['close_val']\n",
        "    code += 1\n",
        "    f.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olb0gCalBiga"
      },
      "source": [
        "# Used only once for train / val / test split. For retraining from scratch resplit again \n",
        "# almost 80 : 20 split\n",
        "\n",
        "# val_size_ps = 100\n",
        "# test_size_ps = 75\n",
        "# train_index = []\n",
        "# validation_index = []\n",
        "# test_index = []\n",
        "# for i in range(X_price_info.__len__()):\n",
        "#   end = len(X_price_info[i])\n",
        "#   indices = np.random.permutation(np.arange(8, end, 1))\n",
        "#   test_index.append(np.sort(indices[-test_size_ps:]))\n",
        "#   validation_index.append(np.sort(indices[:val_size_ps]))\n",
        "#   train_index.append(np.sort(indices[val_size_ps:-test_size_ps]))\n",
        "# f = open('allowed_index', 'wb')\n",
        "# pickle.dump({'train_index' : train_index, 'validation_index' : validation_index, 'test_index' : test_index}, f)\n",
        "# f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yek9nKsy_qI8",
        "outputId": "69531b9f-321c-427e-c4cd-cda1960294da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_index = []\n",
        "validation_index = []\n",
        "test_index = []\n",
        "if os.path.isfile('allowed_index'):\n",
        "  print('reading from file')\n",
        "  f = open('allowed_index', 'rb')\n",
        "  obj = pickle.load(f)\n",
        "  train_index = obj['train_index']\n",
        "  validation_index = obj['validation_index']\n",
        "  test_index = obj['test_index']\n",
        "  f.close()\n",
        "else:\n",
        "  print('file not found')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reading from file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_Q6rVQVwys"
      },
      "source": [
        "# from keras.optimizers import SGD\n",
        "modelFilename=''#'base_best_model.h5'\n",
        "model_interface = cnn_model(modelFilename)\n",
        "model_interface.loadModel()\n",
        "model_interface.compile_model()\n",
        "\n",
        "# sgd = SGD(lr = 0.001, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
        "# need a better optimization/random optimization techique.\n",
        "# maybe try Particle swarm or genectic algorithm"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YLQcjc4XN4Q"
      },
      "source": [
        "# Initialize experience replay object\n",
        "exp_replay = ExperienceReplay()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oknUVPvpYE0G"
      },
      "source": [
        "# temp = exp_replay.memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3ixD4uWYIaV"
      },
      "source": [
        "# exp_replay.memory = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPEdWI3BYPXg"
      },
      "source": [
        "# len(exp_replay.memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0yR1fUadZd"
      },
      "source": [
        "# np.argmax([1,2,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVFDDRiOJlZ"
      },
      "source": [
        "# model_interface.model.save_weights(\"model_checkpoint_day_155.h5\" if modelFilename == None else modelFilename, overwrite=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nna8LW2FS05b"
      },
      "source": [
        "scope = 60\n",
        "p_games = 100\n",
        "v_size = 200\n",
        "env = MarketEnv(X_price_info,\n",
        "        X_indicators,\n",
        "        X_bolinger,\n",
        "        X_adx,\n",
        "        X_onehot,\n",
        "        X_nb,\n",
        "        X_avg_val,\n",
        "        X_close_val,\n",
        "        X_high_val,\n",
        "        X_low_val,\n",
        "        train_index,\n",
        "        validation_index,\n",
        "        v_size,\n",
        "        scope,\n",
        "        parallel_games=p_games)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DdTcW0OsrxZ",
        "outputId": "ffcb7d66-e155-4ba2-c827-f64f69c94602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# parameters\n",
        "epsilon = 0.5  # exploration\n",
        "large_batches = True  # train in large batches for less I/O overhead.\n",
        "batch_size = 32768 if large_batches else 64\n",
        "discount = 0.9    # increasing future discount incentivise future P\n",
        "epoch = 150\n",
        "loss = 0.\n",
        "stop = False\n",
        "update_cycle = 5\n",
        "action = np.zeros(p_games)\n",
        "maximum = -10000\n",
        "\n",
        "for e in range(epoch):\n",
        "  input_t = env.reset()\n",
        "  day_end = False\n",
        "  cumReward, realized_pnl, per_success, num_trades = 0., 0., 0, 0\n",
        "  \n",
        "  while not day_end:\n",
        "    input_tm1 = input_t\n",
        "    isRandom = np.random.rand(p_games) <= epsilon\n",
        "    action[isRandom] = np.random.randint(0, 3, size=np.sum(isRandom))\n",
        "    if np.sum(isRandom) < p_games:\n",
        "      prediction = model_interface.predict(input_tm1, np.logical_not(isRandom))\n",
        "      if np.nan in prediction:\n",
        "        print(\"OCCUR NaN!!!\")\n",
        "        stop = True\n",
        "        break\n",
        "      action[np.logical_not(isRandom)] = np.argmax(prediction, axis=1)\n",
        "    input_t, reward, pnl, success, day_end = env.step(action)\n",
        "    exp_replay.remember([input_tm1, action, reward, input_t], day_end)\n",
        "    cumReward += np.sum(reward)\n",
        "    realized_pnl += np.sum(pnl)\n",
        "    per_success += np.sum(success[success > 0])\n",
        "    num_trades += np.sum(np.abs(success))\n",
        "\n",
        "  \n",
        "  print('epoch =', str(e), 'avgcumReward =', str(cumReward / p_games), 'pnl =', str(realized_pnl / p_games), 'percentage success', str(float(per_success) * 100 / max(num_trades, 1)), 'epsilon=', str(epsilon))\n",
        "  \n",
        "  if stop:\n",
        "    print('stop is True')\n",
        "    break\n",
        "  \n",
        "  # # train\n",
        "  if large_batches:\n",
        "    inputs, targets = exp_replay.get_offline_batch(env, model_interface, batch_size)\n",
        "    model_interface.fitModel(inputs, targets, 64, 10)\n",
        "  else:\n",
        "    inputs, targets = exp_replay.get_online_batch(env, model_interface)\n",
        "    loss = model_interface.batchTrain(inputs, targets)\n",
        "    print('batch = ', str(e), 'loss = ', str(loss))\n",
        "  \n",
        "  if e % 2 == 0:\n",
        "    avg_reward = env.validate(model_interface)\n",
        "    if avg_reward > maximum:\n",
        "      maximum = avg_reward\n",
        "      print('saving best model.....')\n",
        "      model_interface.model.save_weights('base_best_model.h5', overwrite=True)\n",
        "  \n",
        "  if not (e + 1) % update_cycle:\n",
        "    epsilon = epsilon * 0.94\n",
        "    model_interface.model.save_weights('checkpoints/checkpoint_e' + str(epoch), overwrite=True)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch = 0 avgcumReward = 0.15948118175514278 pnl = -0.0010211498925900898 percentage success 49.32076517881897 epsilon= 0.5\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.8940e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.6288e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.5351e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.5149e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4922e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4779e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4428e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4666e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4453e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.4526e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -3.7778515465418105 pnl = -0.007787639637024948 percentage success 67.84351145038168\n",
            "saving best model.....\n",
            "epoch = 1 avgcumReward = 0.1842666653307126 pnl = -0.0005471104972944962 percentage success 52.31594344222331 epsilon= 0.5\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9945e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9947e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9692e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9585e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9380e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9202e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.0047e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9280e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9208e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.8993e-04\n",
            "epoch = 2 avgcumReward = 0.28808639618098253 pnl = 0.005494182122837917 percentage success 52.130713181717816 epsilon= 0.5\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5811e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5582e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5610e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5402e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5402e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5310e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5456e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5524e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5507e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.5136e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -1.6363896784594192 pnl = 0.007512458310741579 percentage success 70.85168869309838\n",
            "saving best model.....\n",
            "epoch = 3 avgcumReward = 0.19745143473101692 pnl = 0.004687411370608821 percentage success 53.455699070926805 epsilon= 0.5\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.8375e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.8271e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7995e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7607e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7520e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7186e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.7486e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7532e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7345e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7186e-04\n",
            "epoch = 4 avgcumReward = 0.20263863467901344 pnl = 0.0004671174593147254 percentage success 53.60956856044425 epsilon= 0.5\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.7007e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.6571e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5703e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5938e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.6232e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5676e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5538e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5895e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5650e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5123e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.1578873580829475 pnl = 0.0016263457602382697 percentage success 61.74863387978142\n",
            "saving best model.....\n",
            "epoch = 5 avgcumReward = 0.13300262615205072 pnl = -0.0006018220474357183 percentage success 54.13961038961039 epsilon= 0.47\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.4342e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.4256e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.3745e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.2847e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.3737e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.2585e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 1.2486e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.2970e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.2065e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.2641e-04\n",
            "epoch = 6 avgcumReward = 0.22229652082706214 pnl = 0.003077705592138782 percentage success 54.401633069660626 epsilon= 0.47\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.9755e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.0625e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5152e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.8372e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5896e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5085e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.8039e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.8372e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.4803e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.5879e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.160782517902195 pnl = -0.0008192306298496438 percentage success 64.27658668181172\n",
            "saving best model.....\n",
            "epoch = 7 avgcumReward = -0.037889201112413125 pnl = -0.009532835913704556 percentage success 55.89562487737885 epsilon= 0.47\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.6699e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.8563e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.5973e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.1109e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0023\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.0717e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 2.8077e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.7423e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 1.8368e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.8331e-04\n",
            "epoch = 8 avgcumReward = 0.2851998058196406 pnl = 0.0036755802307313324 percentage success 52.78121137206428 epsilon= 0.47\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.6288e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.4037e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.2848e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.3495e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.9652e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.7473e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.0085e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.8546e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.2062e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.5686e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.0 pnl = 0.0 percentage success 0.0\n",
            "epoch = 9 avgcumReward = 0.11127816120938128 pnl = 0.0011103510550604778 percentage success 50.562913907284766 epsilon= 0.47\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0552e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.9162e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.7223e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.6248e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.8912e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.3165e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.5551e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.6968e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.2502e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.3178e-04\n",
            "epoch = 10 avgcumReward = 0.0946096330845069 pnl = 0.0007333886707034465 percentage success 49.63318284424379 epsilon= 0.44179999999999997\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.1120e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.4397e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.3615e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.4031e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.3250e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.9872e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.3348e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -3.0137410197140606 pnl = -0.000454874136052828 percentage success 64.0\n",
            "epoch = 11 avgcumReward = 0.23747206615986244 pnl = 0.0038913530101489157 percentage success 51.387018583355776 epsilon= 0.44179999999999997\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0058\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0087\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0072\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0039\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0065\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0083\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0043\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0069\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0050\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0061\n",
            "epoch = 12 avgcumReward = 0.06744897848061213 pnl = -0.002791254754147763 percentage success 50.615114235500876 epsilon= 0.44179999999999997\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0022\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0025\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.004449421060753037 pnl = 5.4002027879423985e-05 percentage success 50.0\n",
            "epoch = 13 avgcumReward = 0.20733513562084302 pnl = 0.0025746422649675126 percentage success 50.05309734513274 epsilon= 0.44179999999999997\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.1467e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.4282e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.8104e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5719e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.7578e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.0904e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.6752e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.7868e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.4838e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 4.3777e-04\n",
            "epoch = 14 avgcumReward = 0.09769512008788611 pnl = -0.0034118275855847258 percentage success 48.42622950819672 epsilon= 0.44179999999999997\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.4042e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.4839e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.3585e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.3074e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.2863e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.4106e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.2707e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.1213e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.1623e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.1682e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -5.078453378513598 pnl = -0.0005706055204692439 percentage success 41.1764705882353\n",
            "epoch = 15 avgcumReward = 0.1627566607266223 pnl = 0.0016896266798304305 percentage success 47.84256559766764 epsilon= 0.41529199999999994\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.0789e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.0187e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.0242e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.8907e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.9144e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.9466e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.9019e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 3.0164e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.7438e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 2.8677e-04\n",
            "epoch = 16 avgcumReward = 0.033512273752601324 pnl = -0.004206965249816509 percentage success 48.66987585507981 epsilon= 0.41529199999999994\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7762e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7748e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.5966e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.5380e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.1634e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.4221e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.4134e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7512e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.5228e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2146e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -6.598261061237532 pnl = 0.008154436243798085 percentage success 50.0\n",
            "epoch = 17 avgcumReward = 0.36708082998193353 pnl = 0.007043731227955097 percentage success 50.65067619290635 epsilon= 0.41529199999999994\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.2442e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.1505e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0502e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0515e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0131e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.9493e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0331e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.1574e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0195e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0189e-04\n",
            "epoch = 18 avgcumReward = 0.15109200621330274 pnl = 0.013924404728600272 percentage success 50.6254786826653 epsilon= 0.41529199999999994\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9070e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.4379e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.6332e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9385e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.3391e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.6005e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5081e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.7067e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5530e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5622e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -1.8679771058964447 pnl = -0.006351178273156268 percentage success 31.242312423124233\n",
            "epoch = 19 avgcumReward = 0.15800473944896162 pnl = -0.0069138386753272675 percentage success 50.17020162346164 epsilon= 0.41529199999999994\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.6374e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.6449e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.5062e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.9026e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.2652e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.2681e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.9151e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.7641e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.6134e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.0339e-04\n",
            "epoch = 20 avgcumReward = 0.25142914836087105 pnl = -0.006697319053796071 percentage success 50.562098501070665 epsilon= 0.3903744799999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.3479e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.7290e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.6609e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.7629e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.6269e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.0207e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.0348e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.7365e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.5983859352042584 pnl = -0.00030197798752903406 percentage success 39.61038961038961\n",
            "epoch = 21 avgcumReward = 0.2603251114903358 pnl = -0.0005421615731254791 percentage success 49.877750611246945 epsilon= 0.3903744799999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.2048e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6690e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.9595e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5891e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3649e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.2222e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.1703e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.1285e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5687e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5004e-04\n",
            "epoch = 22 avgcumReward = 0.2371433271293534 pnl = 0.0030599997986317097 percentage success 50.94395280235988 epsilon= 0.3903744799999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.37873378540147357 pnl = -0.009669228524120572 percentage success 40.78947368421053\n",
            "saving best model.....\n",
            "epoch = 23 avgcumReward = 0.5151770546715998 pnl = 0.0012957264580628835 percentage success 50.06539366989276 epsilon= 0.3903744799999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "epoch = 24 avgcumReward = 0.4204147157207255 pnl = 0.004263465201263983 percentage success 50.0 epsilon= 0.3903744799999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.9023e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.3866e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6841e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8181e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8483e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5099e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3339e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.7082e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.9164e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.4703e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.5173934752875757 pnl = 0.0001768081110457831 percentage success 38.91820580474934\n",
            "epoch = 25 avgcumReward = 0.3424819175876451 pnl = -0.001205974806790192 percentage success 50.98955470038483 epsilon= 0.3669520111999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.8165e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.4632e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.6335e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.3496e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.3142e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.5527e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2533e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2158e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2122e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.0682e-04\n",
            "epoch = 26 avgcumReward = 0.2570422423726392 pnl = -0.0021950067867192104 percentage success 49.416342412451364 epsilon= 0.3669520111999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.9822e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.5357e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.7711e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3594e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.0724e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.7358e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.7243e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.8667e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8073e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 1.0910503310818513 pnl = 0.039470141051876316 percentage success 37.7319257837492\n",
            "saving best model.....\n",
            "epoch = 27 avgcumReward = 0.8363805974244033 pnl = 0.02234937890939013 percentage success 45.563594821020565 epsilon= 0.3669520111999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.8097e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.7609e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.7244e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.6745e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.5669e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.5301e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4711e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.5270e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.5455e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4303e-04\n",
            "epoch = 28 avgcumReward = 0.6799663864424319 pnl = 0.0204058519350084 percentage success 45.41044776119403 epsilon= 0.3669520111999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.8463e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.6787e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5698e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.3185e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2727e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.0579e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2115e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2898e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.3266e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.1184e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.7736069081802117 pnl = 0.03880057944214953 percentage success 39.02889784946237\n",
            "epoch = 29 avgcumReward = 0.7417493252685088 pnl = 0.020346212627470658 percentage success 45.75948160853821 epsilon= 0.3669520111999999\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.3300e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.8306e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2176e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.3141e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1672e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.1153e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.4029e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2354e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9303e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.6519e-04\n",
            "epoch = 30 avgcumReward = 0.5237503181111108 pnl = 0.002663859275920638 percentage success 51.10231769361221 epsilon= 0.34493489052799986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.6344e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.3892e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.3876e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4675e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4535e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.4145e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.3661e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4852e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.2012e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.4747e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.5080931748809039 pnl = -0.0037890296157319374 percentage success 43.85057471264368\n",
            "epoch = 31 avgcumReward = 0.49960607282728836 pnl = -0.00013901104762194415 percentage success 51.164144353899886 epsilon= 0.34493489052799986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.5970e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.3184e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.1362e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2098e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7778e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.7934e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.9449e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.5312e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.8365e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2458e-04\n",
            "epoch = 32 avgcumReward = 0.4418009412598037 pnl = 0.00032071184747610725 percentage success 48.72383137367365 epsilon= 0.34493489052799986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.2446e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.8760e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.3949e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.1922e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.7755e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.8483e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.9391e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.2416e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9574e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.4016e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.3280554574143666 pnl = -0.0061169479578719035 percentage success 32.679245283018865\n",
            "epoch = 33 avgcumReward = 0.4533913253075322 pnl = -0.0004758520893511631 percentage success 51.51342090234152 epsilon= 0.34493489052799986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.2119e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.0758e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.0873e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.8721e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.9642e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.9613e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.8946e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 4.8480e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 4.9346e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.0507e-04\n",
            "epoch = 34 avgcumReward = 0.6128715795618415 pnl = 0.010657356641545412 percentage success 49.896846448570585 epsilon= 0.34493489052799986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.5314e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.9814e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.1918e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.5213e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.2181e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8863e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6352e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4813e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.5317e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.1121e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.5934989982776041 pnl = -0.0014058836551824826 percentage success 43.386243386243386\n",
            "epoch = 35 avgcumReward = 0.4670822180730127 pnl = -0.0006696983854111438 percentage success 50.13591060102688 epsilon= 0.32423879709631986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.8404e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6492e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4789e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4570e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.0525e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3868e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.1132e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.9785e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7372e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.8185e-04\n",
            "epoch = 36 avgcumReward = 0.5485270113994981 pnl = 0.0003479117778999397 percentage success 49.605582524271846 epsilon= 0.32423879709631986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0021\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4251e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0020\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.32806018263746994 pnl = -0.0007634992700799026 percentage success 32.85638579756227\n",
            "epoch = 37 avgcumReward = 0.5317284135257228 pnl = 0.001030238076741009 percentage success 48.76601062168073 epsilon= 0.32423879709631986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.4387e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1611e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2699e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.2148e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.3392e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1917e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9492e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.9851e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.0149e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.1244e-04\n",
            "epoch = 38 avgcumReward = 0.5357777531598799 pnl = -0.0010347325473003554 percentage success 49.91525423728814 epsilon= 0.32423879709631986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0018\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0020\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.8168e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.0846e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.3087e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.9230e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.7722931037703088 pnl = -0.006256560365049333 percentage success 45.878136200716845\n",
            "epoch = 39 avgcumReward = 0.6836846685624528 pnl = 0.005755723106322946 percentage success 50.67016317016317 epsilon= 0.32423879709631986\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.1294e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 8.1503e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.6726e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.2838e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.4857e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.2514e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3768e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.3263e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6856e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.0675e-04\n",
            "epoch = 40 avgcumReward = 0.6246376383395202 pnl = 0.0031626173871421638 percentage success 49.01021711366539 epsilon= 0.30478446927054065\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.6155e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.3420e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2867e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.3171e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.2623e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.1934e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.1580e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.1617e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1308e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.0849e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.07420018509180389 pnl = 0.0012063226909070845 percentage success 58.48915482423336\n",
            "epoch = 41 avgcumReward = 0.43138685563252893 pnl = 0.0047755584155321626 percentage success 49.65403624382208 epsilon= 0.30478446927054065\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6581e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4330e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.6676e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4102e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4883e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.3319e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4043e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5598e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4713e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.2702e-04\n",
            "epoch = 42 avgcumReward = 0.5123040258620616 pnl = 0.003256689333981818 percentage success 50.20472440944882 epsilon= 0.30478446927054065\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.0750e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.0992e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.9380e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.9135e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.9487e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.9992e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 5.8259e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.0076e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9528e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.9480e-04\n",
            "epoch = 43 avgcumReward = -0.002656203378673552 pnl = -0.0005123900384435742 percentage success 50.774193548387096 epsilon= 0.30478446927054065\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.8001e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.9486e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.2823e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1933e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.5462e-04\n",
            "epoch = 44 avgcumReward = 0.0091903724730411 pnl = 0.0023702704327499356 percentage success 49.34585709493459 epsilon= 0.30478446927054065\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "....................Validation Result.....................\n",
            "avgReward = -3.56462236616371 pnl = 0.0018147396842123297 percentage success 36.0\n",
            "epoch = 45 avgcumReward = 0.21720413156875573 pnl = 0.018019218266983564 percentage success 50.600706713780916 epsilon= 0.2864974011143082\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "epoch = 46 avgcumReward = -0.48465197087174394 pnl = -0.011558642258288248 percentage success 48.28440042447824 epsilon= 0.2864974011143082\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0036\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0020\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0019\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "....................Validation Result.....................\n",
            "avgReward = -7.024487805240763 pnl = -0.004307052208009701 percentage success 46.0\n",
            "epoch = 47 avgcumReward = -0.15964088493098733 pnl = -0.0029190724773033782 percentage success 50.761232825844786 epsilon= 0.2864974011143082\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "epoch = 48 avgcumReward = -0.1280501987282417 pnl = -0.013694064324012468 percentage success 49.858557284299856 epsilon= 0.2864974011143082\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "....................Validation Result.....................\n",
            "avgReward = -4.621203567705165 pnl = -0.005583003596109769 percentage success 47.27272727272727\n",
            "epoch = 49 avgcumReward = -0.46163578209515643 pnl = -0.01579007694968724 percentage success 48.13186813186813 epsilon= 0.2864974011143082\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "epoch = 50 avgcumReward = 0.020396132821978066 pnl = 0.01133359840773681 percentage success 50.07680491551459 epsilon= 0.2693075570474497\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "....................Validation Result.....................\n",
            "avgReward = -3.7941617747085075 pnl = 0.0012184122120397533 percentage success 51.21951219512195\n",
            "epoch = 51 avgcumReward = -0.39800246429086683 pnl = -0.003435091300501305 percentage success 49.53739398612182 epsilon= 0.2693075570474497\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0019\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "epoch = 52 avgcumReward = 0.3177864939738605 pnl = -0.005252673892075406 percentage success 48.15217391304348 epsilon= 0.2693075570474497\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0018\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0015\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "....................Validation Result.....................\n",
            "avgReward = -2.552412073811768 pnl = 0.004803123915591776 percentage success 27.634660421545668\n",
            "epoch = 53 avgcumReward = 0.40416049268720244 pnl = 0.005630811574320613 percentage success 51.69008735282947 epsilon= 0.2693075570474497\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "epoch = 54 avgcumReward = 0.4931031843644863 pnl = -0.002703040727175633 percentage success 50.086355785837654 epsilon= 0.2693075570474497\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.7616724330920184 pnl = -0.0006690506395612894 percentage success 46.017699115044245\n",
            "epoch = 55 avgcumReward = 0.5016329564435567 pnl = 0.003971701584475181 percentage success 50.10570824524313 epsilon= 0.2531491036246027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "epoch = 56 avgcumReward = 0.8371903614919768 pnl = 0.015697450630748934 percentage success 48.927038626609445 epsilon= 0.2531491036246027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.3490003834554187 pnl = -0.0015566540368715564 percentage success 41.964285714285715\n",
            "epoch = 57 avgcumReward = 0.2440096347016312 pnl = -0.006078066709059945 percentage success 49.670619235836625 epsilon= 0.2531491036246027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "epoch = 58 avgcumReward = 0.4515961323132957 pnl = 0.006319434017670941 percentage success 52.3120037365717 epsilon= 0.2531491036246027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0018\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0019\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.3929283067843919 pnl = 0.0010866507185167994 percentage success 52.667313288069835\n",
            "epoch = 59 avgcumReward = 0.39006605877353756 pnl = 4.7537752655471e-05 percentage success 50.02068680182044 epsilon= 0.2531491036246027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "epoch = 60 avgcumReward = 0.1354628985495868 pnl = 0.0040252951437172065 percentage success 51.32786093674553 epsilon= 0.2379601574071265\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.8839e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.6368e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.7556e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1317e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.0073e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.5170e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.0844e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.6214e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 5.8131e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 6.1463e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -4.992417764291897 pnl = -0.007377481495695939 percentage success 63.36734693877551\n",
            "epoch = 61 avgcumReward = -0.07728219945282429 pnl = -0.005035038138850423 percentage success 49.63476990504017 epsilon= 0.2379601574071265\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "epoch = 62 avgcumReward = -0.4659540823332174 pnl = 0.0012870962142873133 percentage success 49.174174174174176 epsilon= 0.2379601574071265\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.9819e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 9.7113e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "....................Validation Result.....................\n",
            "avgReward = -5.514479053382896 pnl = -0.007314809717860249 percentage success 52.12765957446808\n",
            "epoch = 63 avgcumReward = -0.20988932779725356 pnl = 0.004358320564825314 percentage success 51.92147034252297 epsilon= 0.2379601574071265\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0022\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "epoch = 64 avgcumReward = -0.27361864185557994 pnl = 0.0017630949619866665 percentage success 50.134529147982065 epsilon= 0.2379601574071265\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0052\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0033\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0036\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0029\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0034\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0026\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0028\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0026\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0032\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0029\n",
            "....................Validation Result.....................\n",
            "avgReward = -7.013942232374523 pnl = -0.000673008639367183 percentage success 47.5\n",
            "epoch = 65 avgcumReward = -0.49699782895208444 pnl = 0.003683535468745612 percentage success 48.18875119161106 epsilon= 0.2236825479626989\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0016\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "epoch = 66 avgcumReward = -0.3322909943744355 pnl = 0.004702791000110883 percentage success 49.440214957456334 epsilon= 0.2236825479626989\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0016\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.34891301670356895 pnl = 0.006761981003375601 percentage success 42.19985621854781\n",
            "epoch = 67 avgcumReward = 0.43905120550839905 pnl = -0.005765349063014994 percentage success 49.55937893411666 epsilon= 0.2236825479626989\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0015\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0014\n",
            "epoch = 68 avgcumReward = 0.2461403888433676 pnl = -0.005036256446674306 percentage success 49.01960784313726 epsilon= 0.2236825479626989\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0022\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0027\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0022\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0022\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0021\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0021\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0019\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0020\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.5992132030837903 pnl = 0.003057075609048707 percentage success 41.07338444687842\n",
            "epoch = 69 avgcumReward = 0.7434509135689352 pnl = 0.009080247577419561 percentage success 49.76617303195635 epsilon= 0.2236825479626989\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0019\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0020\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0018\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0017\n",
            "epoch = 70 avgcumReward = 0.5685621382983497 pnl = -0.0005521262011129235 percentage success 48.6718430731508 epsilon= 0.21026159508493697\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0012\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.5413262978258484 pnl = -0.0008952222535893029 percentage success 43.293413173652695\n",
            "epoch = 71 avgcumReward = 0.6136281871945707 pnl = 0.003596477204144607 percentage success 50.24232633279483 epsilon= 0.21026159508493697\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 5s 10ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "epoch = 72 avgcumReward = 0.6272408108993557 pnl = 0.0011866514931853467 percentage success 50.22150624244865 epsilon= 0.21026159508493697\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.9954e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.8463e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.40145742446501204 pnl = -0.003430157522810564 percentage success 47.12793733681462\n",
            "epoch = 73 avgcumReward = 0.0029426568458510395 pnl = -0.006221817967566082 percentage success 47.46393671475105 epsilon= 0.21026159508493697\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.9916e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.8720e-04\n",
            "epoch = 74 avgcumReward = 0.23061445188594604 pnl = -0.004617966302194125 percentage success 49.84212900315742 epsilon= 0.21026159508493697\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.9186e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.9643e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.9658e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.9763e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -4.2112335628513895 pnl = 0.0030486585906054488 percentage success 73.81275440976934\n",
            "epoch = 75 avgcumReward = -0.3584074084126462 pnl = 0.0003404086889957492 percentage success 48.82217090069284 epsilon= 0.19764589937984073\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0018\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0017\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0017\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0016\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0017\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0017\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0016\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0017\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0017\n",
            "epoch = 76 avgcumReward = 0.3302390425346157 pnl = 0.004083248893118927 percentage success 51.282051282051285 epsilon= 0.19764589937984073\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0012\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.32570140629645705 pnl = -0.002727064970199147 percentage success 46.81970349115256\n",
            "epoch = 77 avgcumReward = 0.6068417908119956 pnl = -0.0004683980473630067 percentage success 51.40988966080916 epsilon= 0.19764589937984073\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1507e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.7915e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6201e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.3098e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.4352e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.4627e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6528e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1329e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4361e-04\n",
            "epoch = 78 avgcumReward = 0.6544635519927807 pnl = 0.007716829952173921 percentage success 51.55723905723906 epsilon= 0.19764589937984073\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6984e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.7585e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.8588e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4901e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5572e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5821e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5103e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.5156e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6407e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5313e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.8742590747613722 pnl = -0.0013636649391646565 percentage success 46.71503426037888\n",
            "epoch = 79 avgcumReward = 0.6972730345046081 pnl = -0.0026347810548299645 percentage success 48.94271434063822 epsilon= 0.19764589937984073\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.7558e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.8222e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5433e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6571e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4166e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.4248e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.6180e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4535e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.3481e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4270e-04\n",
            "epoch = 80 avgcumReward = 0.7896827223762652 pnl = 0.0029996123083225134 percentage success 49.70107612594659 epsilon= 0.18578714541705027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.8845e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.1733e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.7437e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.8952e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4669e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5315e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5382e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.0188e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.2744e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.6206e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.6671227157616871 pnl = -0.008346370292177965 percentage success 43.252747252747255\n",
            "epoch = 81 avgcumReward = 0.6959394725518703 pnl = 0.0034561466263016904 percentage success 48.793906051629286 epsilon= 0.18578714541705027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.6141e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.6503e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.7147e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4503e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.3758e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.5146e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4489e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4504e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.4373e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.5022e-04\n",
            "epoch = 82 avgcumReward = 0.6367822605805857 pnl = 0.0012665987651987798 percentage success 50.64157399486741 epsilon= 0.18578714541705027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.6773e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4137e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.1533e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.2359e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5865e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.1705e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0582e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.1094e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.2461e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0791e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.6876834866856102 pnl = -0.00414480845337768 percentage success 38.71841155234657\n",
            "epoch = 83 avgcumReward = 0.6184830001583719 pnl = -0.005190242028493798 percentage success 46.3810316139767 epsilon= 0.18578714541705027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.1506e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0403e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9899e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.2049e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9568e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9695e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0416e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9192e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9820e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9295e-04\n",
            "epoch = 84 avgcumReward = 0.384577996204462 pnl = -0.0014528810081570775 percentage success 52.591333899745116 epsilon= 0.18578714541705027\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.7541e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.5154e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.3684e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.1420e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.9782e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1637e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.9949e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.2514e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.9174e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1451e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -2.7879118632006037 pnl = -0.0018659407743372048 percentage success 67.52232142857143\n",
            "epoch = 85 avgcumReward = 0.10208608953287948 pnl = 0.008375579981762346 percentage success 50.96642929806714 epsilon= 0.17463991669202725\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "epoch = 86 avgcumReward = 0.37627142685986575 pnl = -0.013551285384606322 percentage success 49.204906860517944 epsilon= 0.17463991669202725\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.7824e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.7373e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.8262e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.7276e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.6388e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.7298e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.6008e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.6059e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.5818e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.6769998818755424 pnl = -0.0033451129881771125 percentage success 65.23235800344234\n",
            "epoch = 87 avgcumReward = 0.2789187437343883 pnl = 0.004032163537078189 percentage success 51.4004914004914 epsilon= 0.17463991669202725\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "epoch = 88 avgcumReward = -0.2169878841010268 pnl = -0.0018420735242776697 percentage success 51.47426286856572 epsilon= 0.17463991669202725\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.6809022963153433 pnl = 0.003519352153301616 percentage success 65.1414309484193\n",
            "epoch = 89 avgcumReward = -0.38755375876100884 pnl = -0.014031166928729976 percentage success 50.31599416626155 epsilon= 0.17463991669202725\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "epoch = 90 avgcumReward = 0.39243684192196876 pnl = 0.013570677517766291 percentage success 51.09366236679753 epsilon= 0.1641615216905056\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.49210195174759086 pnl = -0.011271517646533549 percentage success 56.19469026548673\n",
            "epoch = 91 avgcumReward = 0.24093083532201548 pnl = 0.004287033290973781 percentage success 52.215508559919435 epsilon= 0.1641615216905056\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "epoch = 92 avgcumReward = 0.34945472120387266 pnl = -0.003557611993019819 percentage success 50.178480367159615 epsilon= 0.1641615216905056\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0014\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0013\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.02867430538768837 pnl = 0.0006824212799949087 percentage success 36.61417322834646\n",
            "epoch = 93 avgcumReward = 0.24932735789362812 pnl = -0.0031630360202704023 percentage success 47.78809393773894 epsilon= 0.1641615216905056\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "epoch = 94 avgcumReward = 0.2045212990210772 pnl = 0.000500082937632148 percentage success 48.06565064478312 epsilon= 0.1641615216905056\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0012\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.9253018462912229 pnl = -0.0006295342382011127 percentage success 41.7574931880109\n",
            "epoch = 95 avgcumReward = 0.20558792453699376 pnl = -0.0005677267879910097 percentage success 46.12109744560075 epsilon= 0.15431183038907526\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0011\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0011\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 0.0010\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 0.0010\n",
            "epoch = 96 avgcumReward = -0.2643639035507986 pnl = -0.0013668737536242993 percentage success 43.96798170383076 epsilon= 0.15431183038907526\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.4817e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.3662e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.3175e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.1284e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 9.4588e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.2867e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.1855e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.2059e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.3086e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 9.6288e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.06035070080167799 pnl = 0.001826363398011543 percentage success 37.524177949709866\n",
            "epoch = 97 avgcumReward = 0.24857480456105438 pnl = -0.004747825451186537 percentage success 44.40059200789344 epsilon= 0.15431183038907526\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0523e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0454e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.0609e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8209e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.9666e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.8092e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 5s 9ms/step - loss: 7.9266e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.8718e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.7934e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.9386e-04\n",
            "epoch = 98 avgcumReward = 0.27512114113961156 pnl = -0.011282544586985625 percentage success 41.40094093047569 epsilon= 0.15431183038907526\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.6686e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5892e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.6155e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.5662e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5104e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4230e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4591e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 8.3720e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.4622e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 8.5389e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = -0.33729491345427426 pnl = 0.0038005548614612737 percentage success 35.67438148443735\n",
            "epoch = 99 avgcumReward = 0.30593220424285184 pnl = -0.004843436558266417 percentage success 45.40318438623523 epsilon= 0.15431183038907526\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.7900e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5902e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5462e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.4594e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5534e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 7.5373e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5502e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5865e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.4964e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.4759e-04\n",
            "epoch = 100 avgcumReward = 0.3982620899320268 pnl = 0.0010334944802123448 percentage success 44.658590308370044 epsilon= 0.14505312056573072\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.6733e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 9ms/step - loss: 6.5709e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.4665e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.4943e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.6877e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.4891e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.4575e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.5501e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.5942e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 6.5104e-04\n",
            "....................Validation Result.....................\n",
            "avgReward = 0.13801649867294846 pnl = -0.002100240777764285 percentage success 36.20283018867924\n",
            "epoch = 101 avgcumReward = 0.5855534071753747 pnl = -0.0034574427163478706 percentage success 45.31610521458237 epsilon= 0.14505312056573072\n",
            "Epoch 1/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.7666e-04\n",
            "Epoch 2/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.6279e-04\n",
            "Epoch 3/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5770e-04\n",
            "Epoch 4/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.6622e-04\n",
            "Epoch 5/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.7329e-04\n",
            "Epoch 6/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.6045e-04\n",
            "Epoch 7/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5049e-04\n",
            "Epoch 8/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5333e-04\n",
            "Epoch 9/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.5264e-04\n",
            "Epoch 10/10\n",
            "512/512 [==============================] - 4s 8ms/step - loss: 7.4983e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-1b6a6e3772cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misRandom\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misRandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misRandom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mp_games\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misRandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OCCUR NaN!!!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-45b712354c58>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, sub_sample)\u001b[0m\n\u001b[1;32m    202\u001b[0m                       \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                       \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                       data['onehot'][sub_sample]])\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZZSxmlKb9Kn"
      },
      "source": [
        "class MarketEnv(object):\n",
        "\n",
        "    ON_PROFIT_HOLDING = 0.9\n",
        "    ON_LOSS_HOLDING = np.array([4.0, 3.0, 2.0, 1.0, 0.3, 0.9, 2.0, 3.0, 4.0])\n",
        "\n",
        "    def __init__(self, x_price_info, x_indicators, x_bolinger, x_adx, x_onehot, x_nb, x_avg_val, x_close_val, x_high_val, x_low_val, training_index, validation_index, validation_size, scope, parallel_games=1):        \n",
        "        max_size = 0\n",
        "        self.index_end = []\n",
        "        self.num_target = X_price_info.__len__()\n",
        "        for key in X_price_info.keys():\n",
        "            self.index_end.append(len(X_price_info[key]))\n",
        "            max_size = max(max_size, self.index_end[-1])\n",
        "\n",
        "        self.X_price_info = self._copy_table(x_price_info, max_size)\n",
        "        self.X_indicators = self._copy_table(x_indicators, max_size)\n",
        "        self.X_bolinger = self._copy_table(x_bolinger, max_size)\n",
        "        self.X_adx = self._copy_table(x_adx, max_size)\n",
        "        self.X_onehot = self._copy_table(x_onehot, max_size)\n",
        "        self.X_nb = self._copy_table(x_nb, max_size)\n",
        "\n",
        "        self.X_avg_val = x_avg_val\n",
        "        self.X_close_val = x_close_val\n",
        "        self.X_high_val = x_high_val\n",
        "        self.X_low_val = x_low_val\n",
        "        self.scope = scope\n",
        "        self.parallel_games = parallel_games\n",
        "        self.training_index = training_index\n",
        "        self.validation_index = validation_index\n",
        "        self.validation_size_ps = validation_size // self.num_target\n",
        "        self.validation_size = self.validation_size_ps * self.num_target\n",
        "        \n",
        "        self.done = False\n",
        "        self.constant = 10.\n",
        "        self.position, self.reward, self.boughts, self.budget, self.position, self.realized_pnl, self.success, self.num_position, self.cum_reward = [np.zeros((parallel_games, 1)) for _ in range(9)]\n",
        "        self.val_position, self.val_reward, self.val_boughts, self.val_budget, self.val_position, self.val_realized_pnl, self.val_success, self.val_num_position, self.val_cum_reward = [np.zeros((self.validation_size, 1)) for _ in range(9)]\n",
        "        self.num_days = self.X_price_info.shape[1]\n",
        "        self.episode_length = self.X_price_info.shape[2]\n",
        "        self.targetContext = np.zeros((self.num_target, self.num_days), dtype=bool)\n",
        "        self.validation_codes = np.hstack([i * np.ones(self.validation_size_ps, dtype=int) for i in range(self.num_target)])\n",
        "\n",
        "        self.actions = [\n",
        "            \"LONG\",\n",
        "            \"HOLD\",\n",
        "            \"SHORT\"\n",
        "        ]\n",
        "\n",
        "        self._seed()\n",
        "    \n",
        "    def _copy_table(self, x_array, max_size):\n",
        "        X_array = np.empty([self.num_target, max_size] + list(x_array[0].shape[1:]))\n",
        "        for i in range(self.num_target):\n",
        "            diff = max_size - x_array[i].shape[0]\n",
        "            if diff > 0:\n",
        "                X_array[i] = np.concatenate([x_array[i], np.zeros([diff] + list(x_array[0].shape[1:]))], axis=0)\n",
        "            else:\n",
        "                X_array[i] = x_array[i]\n",
        "        return X_array\n",
        "    \n",
        "    def _get_holding_mutiplier(self, x, diff):\n",
        "        return (diff < 0) * self.ON_LOSS_HOLDING[np.clip(((0.02 - x) / 0.005).astype(int), 0, 8)] + (diff >= 0) * self.ON_PROFIT_HOLDING\n",
        "    \n",
        "    def validate(self, interface):\n",
        "        temp = self.parallel_games\n",
        "        self.parallel_games = self.validation_size       # work around\n",
        "        input_t = self.reset(False)\n",
        "        avgReward, pnl, per_success, num_trades = 0., 0., 0, 0\n",
        "        games = self.validation_size\n",
        "\n",
        "        while not self.done:\n",
        "            action = np.argmax(interface.predict(input_t), axis=1)\n",
        "            input_t, validation_reward, validation_pnl, validation_success, _ = self._validation_step(action)\n",
        "            avgReward += np.sum(validation_reward)\n",
        "            pnl += np.sum(validation_pnl)\n",
        "            per_success += np.sum(validation_success[validation_success > 0])\n",
        "            num_trades += np.sum(np.abs(validation_success))\n",
        "        \n",
        "        print('....................Validation Result.....................')\n",
        "        print('avgReward =', str(avgReward / games), 'pnl =', str(pnl / games), 'percentage success', str(float(per_success) * 100 / max(num_trades, 1)))\n",
        "        self.parallel_games = temp\n",
        "\n",
        "        return avgReward\n",
        "\n",
        "    def _create_hourly_price_till(self, index, timesteps, code):\n",
        "        minutes = timesteps * 60\n",
        "        hourly_avg_price, hourly_close_price, hourly_high_price, hourly_low_price = [], [], [], []\n",
        "\n",
        "        for k in range(self.parallel_games):\n",
        "            start = max((index[k] + 1) % 60, index[k] - minutes + 1)\n",
        "            end = min(len(self.X_close_val[code[k]]), index[k] + 1)\n",
        "            temp = np.array(np.split(X_avg_val[code[k]][start:end], (end - start) // 60))\n",
        "            hourly_avg_price.append(np.average(temp, axis=1))\n",
        "            hourly_close_price.append(temp[:, -1])\n",
        "            hourly_high_price.append(np.max(temp, axis=1))\n",
        "            hourly_low_price.append(np.min(temp, axis=1))\n",
        "        \n",
        "        return (hourly_avg_price, hourly_close_price, hourly_high_price, hourly_low_price)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done:\n",
        "            return self.state, self.reward, self.realized_pnl, self.success, self.done\n",
        "\n",
        "        vari = np.expand_dims(self.target_price[:, self.currentTargetIndex, 1] / 100, axis=1)\n",
        "        change = self.boughts * vari\n",
        "        self.boughts += change\n",
        "        self.cum_reward = self.boughts - self.num_position * self.position\n",
        "        action = (-self.position) * self.last + (1. - self.last) * np.expand_dims(1 - action, axis=1)\n",
        "        distribute = np.abs(np.sign(action + self.position))\n",
        "        self.realized_pnl = (1 - distribute) * self.cum_reward\n",
        "        self.reward = (self.realized_pnl + distribute * self._get_holding_mutiplier(np.divide(self.cum_reward, np.sqrt(self.num_position), np.zeros_like(self.num_position), where=self.num_position!=0), change) * change) * self.constant\n",
        "        new_position = (self.budget >= 1) * action * distribute\n",
        "        self.budget += (1 - distribute) * (self.num_position + self.cum_reward) - np.abs(new_position)\n",
        "        self.position = np.sign(self.position * distribute + new_position)\n",
        "        self.boughts = self.boughts * distribute + new_position\n",
        "        self.num_position = np.abs(self.position * self.num_position + new_position)\n",
        "        self.cum_reward = self.cum_reward * distribute\n",
        "        self.success = np.sign(self.realized_pnl)\n",
        "        self.currentTargetIndex += 1\n",
        "        \n",
        "        if self.currentTargetIndex >= self.episode_length:\n",
        "            self.done = True\n",
        "        \n",
        "        if self.currentTargetIndex + 1 == self.episode_length:\n",
        "            self.last = 1.\n",
        "\n",
        "        # print('  current_price=',str(self.target_price[0, self.currentTargetIndex - 1, 0]),'  realized_pnl=',str(self.realized_pnl[0][0]),'  success=',str(self.success[0][0]), '  position=',str(self.position[0][0]),'  new_position=',str(new_position[0][0]),'  num_position=',str(self.num_position[0][0]),'  cum_reward=',str(self.cum_reward[0][0]), '  reward=', str(self.reward[0][0]))\n",
        "        \n",
        "        self._defineState(self.cum_reward, self.budget, self.position, self.num_position)\n",
        "        return self.state, self.reward, self.realized_pnl, self.success, self.done\n",
        "    \n",
        "    def _validation_step(self, action):\n",
        "        if self.done:\n",
        "            return self.state, self.val_reward, self.val_realized_pnl, self.val_success, self.done\n",
        "\n",
        "        vari = np.expand_dims(self.target_price[:, self.currentTargetIndex, 1] / 100, axis=1)\n",
        "        change = self.val_boughts * vari\n",
        "        self.val_boughts += change\n",
        "        self.val_cum_reward = self.val_boughts - self.val_num_position * self.val_position\n",
        "        action = (-self.val_position) * self.last + (1. - self.last) * np.expand_dims(1 - action, axis=1)\n",
        "        distribute = np.abs(np.sign(action + self.val_position))\n",
        "        self.val_realized_pnl = (1 - distribute) * self.val_cum_reward\n",
        "        self.val_reward = (self.val_realized_pnl + distribute * self._get_holding_mutiplier(np.divide(self.val_cum_reward, np.sqrt(self.val_num_position), np.zeros_like(self.val_num_position), where=self.val_num_position!=0), change) * change) * self.constant\n",
        "        new_position = (self.val_budget >= 1) * action * distribute\n",
        "        self.val_budget += (1 - distribute) * (self.val_num_position + self.val_cum_reward) - np.abs(new_position)\n",
        "        self.val_position = np.sign(self.val_position * distribute + new_position)\n",
        "        self.val_boughts = self.val_boughts * distribute + new_position\n",
        "        self.val_num_position = np.abs(self.val_position * self.val_num_position + new_position)\n",
        "        self.val_cum_reward = self.val_cum_reward * distribute\n",
        "        self.val_success = np.sign(self.val_realized_pnl)\n",
        "        self.currentTargetIndex += 1\n",
        "\n",
        "        if self.currentTargetIndex >= self.episode_length:\n",
        "            self.done = True\n",
        "        \n",
        "        if self.currentTargetIndex + 1 == self.episode_length:\n",
        "            self.last = 1.\n",
        "\n",
        "        print('budget=',str(self.val_budget[0][0]),'bought=',str(self.val_boughts[0][0]),'position=',str(self.val_position[0][0]),'distribute=',str(distribute[0][0]),'new_position=',str(new_position[0][0]),'num_position=',str(self.val_num_position[0][0]),'cum_reward=',str(self.val_cum_reward[0][0]))\n",
        "        \n",
        "        self._defineState(self.val_cum_reward, self.val_budget, self.val_position, self.val_num_position)\n",
        "        return self.state, self.val_reward, self.val_realized_pnl, self.val_success, self.done\n",
        "\n",
        "    def reset(self, train=True):\n",
        "        self.targetContext *= False\n",
        "\n",
        "        if train:\n",
        "            x = np.array([np.random.rand() for _ in range(self.num_target)])\n",
        "            x = (x / np.sum(x)) * (self.parallel_games - self.num_target)\n",
        "            y = []\n",
        "            for i in range(self.num_target - 1):\n",
        "                y.append(1 + int(x[i]))\n",
        "            y.append(self.parallel_games - sum(y))\n",
        "            y = np.random.permutation(y)\n",
        "            self.targetDays = []\n",
        "            self.targetCode = np.hstack([i * np.ones(y[i], dtype=int) for i in range(self.num_target)])\n",
        "            for i in range(self.num_target):\n",
        "                selection = self.training_index[i][np.sort(np.random.choice(len(self.training_index[i]), size=y[i], replace=False))]\n",
        "                self.targetContext[i][selection] = True\n",
        "                self.targetDays = self.targetDays + list(selection)\n",
        "        \n",
        "            self.targetDays = np.array(self.targetDays)\n",
        "            self.target_price = self.X_price_info[self.targetContext]\n",
        "            self.target_indicators = self.X_indicators[self.targetContext]\n",
        "            self.target_nb = self.X_nb[self.targetContext]\n",
        "            self.target_bolinger = self.X_bolinger[self.targetContext]\n",
        "            self.target_adx = self.X_adx[self.targetContext]\n",
        "            self.target_onehot = self.X_onehot[self.targetContext]\n",
        "            self.currentTargetIndex = self.scope - 1\n",
        "            self.done = False\n",
        "            self.last = 0.\n",
        "            self.budget = self.budget * 0. + 8. \n",
        "            self.position = self.position * 0.\n",
        "            self.num_position = self.num_position * 0.\n",
        "            self.boughts = self.boughts * 0.\n",
        "            self.cum_reward = self.cum_reward * 0.\n",
        "            self._defineState(self.cum_reward, self.budget, self.position, self.num_position)\n",
        "        else:\n",
        "            self.targetCode = self.validation_codes\n",
        "            self.targetDays = []\n",
        "            for i in range(self.num_target):\n",
        "                selection = self.validation_index[i][np.sort(np.random.choice(len(self.validation_index[i]), size=self.validation_size_ps, replace=False))]\n",
        "                self.targetContext[i][selection] = True\n",
        "                self.targetDays = self.targetDays + list(selection)\n",
        "\n",
        "            self.targetDays = np.array(self.targetDays)\n",
        "            self.target_price = self.X_price_info[self.targetContext]\n",
        "            self.target_indicators = self.X_indicators[self.targetContext]\n",
        "            self.target_nb = self.X_nb[self.targetContext]\n",
        "            self.target_bolinger = self.X_bolinger[self.targetContext]\n",
        "            self.target_adx = self.X_adx[self.targetContext]\n",
        "            self.target_onehot = self.X_onehot[self.targetContext]\n",
        "            self.currentTargetIndex = self.scope - 1\n",
        "            self.done = False\n",
        "            self.last = 0.\n",
        "            self.val_budget = self.val_budget * 0. + 8. \n",
        "            self.val_position = self.val_position * 0.\n",
        "            self.val_num_position = self.val_num_position * 0.\n",
        "            self.val_boughts = self.val_boughts * 0.\n",
        "            self.val_cum_reward = self.val_cum_reward * 0.\n",
        "            self._defineState(self.val_cum_reward, self.val_budget, self.val_position, self.val_num_position)\n",
        "            \n",
        "\n",
        "        return self.state\n",
        "\n",
        "    def _render(self, mode='human', close=False):\n",
        "        if close:\n",
        "            return\n",
        "        return self.state\n",
        "\n",
        "    def _seed(self):\n",
        "        return int(random.random() * 100)\n",
        "\n",
        "    def _create_hourly_data(self, code, day, index):\n",
        "        timesteps = 80\n",
        "        lookback = self.scope // 2\n",
        "        # adjusting day_ignored and index_ignored\n",
        "        end = (day + 4) * 375 + (index + 30)\n",
        "        hourly_avg_val, hourly_close_val, hourly_high_val, hourly_low_val = self._create_hourly_price_till(end, timesteps, code)\n",
        "        hourly_rsi, hourly_atr, X_avg_price = [], [], []\n",
        "        for i in range(self.parallel_games):\n",
        "          hourly_rsi.append(np.expand_dims((RSI(hourly_close_val[i], timeperiod=14)[-lookback:]) / 100, axis=(0, 2)))\n",
        "          hourly_atr.append(np.expand_dims(NATR(hourly_high_val[i], hourly_low_val[i], hourly_close_val[i], timeperiod=14)[-lookback:], axis=(0, 2)))\n",
        "          X_avg_price.append(np.expand_dims((hourly_avg_val[i][-lookback:] - hourly_avg_val[i][-(lookback + 1) : -1]) * 10 / hourly_avg_val[i][-(lookback + 1) : -1], axis=(0, 2)))\n",
        "        hourly_data = np.concatenate([X_avg_price, hourly_rsi, hourly_atr], axis=3)\n",
        "\n",
        "        return hourly_data\n",
        "\n",
        "    def _standardize(self, X_array):\n",
        "        n = X_array.shape[2]\n",
        "        for i in range(n):\n",
        "            temp = X_array[:, :, i]\n",
        "            X_array[:, :, i] = (temp - np.mean(temp, axis=1, keepdims=True)) / np.std(temp, axis=1, keepdims=True)\n",
        "\n",
        "    # to prevent memory overflow create training data in an online way\n",
        "    def generate_data(self, code, day, index):\n",
        "        r_data = {}\n",
        "\n",
        "        if index < self.scope - 1:\n",
        "            print('index not in range =', str(index))\n",
        "            return None\n",
        "\n",
        "        # normalize prices\n",
        "        price_curve = np.array(self.target_price[:, index - self.scope + 1 : index + 1])\n",
        "        r_data['scale'] = np.array(price_curve[:, self.scope // 2:, 1])\n",
        "        self._standardize(price_curve)\n",
        "        price_curve = np.expand_dims(price_curve, axis=1)\n",
        "\n",
        "        # normalize nb prices\n",
        "        nb_price = np.array(self.target_nb[:, index - (self.scope // 2) + 1 : index + 1])\n",
        "        self._standardize(nb_price)\n",
        "        nb_price = np.expand_dims(nb_price, axis=1)\n",
        "\n",
        "        indicators = self.target_indicators[:, index - self.scope + 1 : index + 1]\n",
        "        indicators = np.expand_dims(indicators, axis=1)\n",
        "\n",
        "        bolinger = self.target_bolinger[:, index - self.scope + 1 : index + 1]\n",
        "        bolinger = np.swapaxes(bolinger, 1, 2)\n",
        "        bolinger = np.expand_dims(bolinger, axis=3)\n",
        "\n",
        "        adx = self.target_adx[:, index - self.scope + 1 : index + 1]\n",
        "        adx = np.expand_dims(adx, axis=1)\n",
        "\n",
        "        onehot = self.target_onehot[:, index - (self.scope // 2) + 1 : index + 1]\n",
        "        onehot = np.swapaxes(onehot, 1, 2)\n",
        "        onehot = np.expand_dims(onehot, axis=3)\n",
        "\n",
        "        r_data['price_curve'] = price_curve\n",
        "        r_data['indicators'] = indicators\n",
        "        r_data['bolinger'] = bolinger\n",
        "        r_data['adx'] = adx\n",
        "        r_data['onehot'] = onehot\n",
        "        r_data['nb'] = nb_price\n",
        "        r_data['hourly_data'] = self._create_hourly_data(code, day, index)\n",
        "\n",
        "        return r_data\n",
        "\n",
        "    def _defineState(self, x_cum_reward, x_budget, x_position, x_num_position):\n",
        "        if self.done:\n",
        "            return\n",
        "        \n",
        "        tmpState = self.generate_data(self.targetCode, self.targetDays, self.currentTargetIndex)\n",
        "        \n",
        "        onehot_code = np.zeros((self.parallel_games, self.num_target), dtype=float)\n",
        "        for i in range(self.parallel_games):\n",
        "            onehot_code[self.targetCode[i]] = 1.0\n",
        "\n",
        "        tmpState['portfolio'] = np.concatenate([self.last * np.ones((self.parallel_games, 1)), x_cum_reward * self.constant, x_budget / 8, x_position, x_num_position / 8, (float(self.currentTargetIndex) / self.episode_length) * np.ones((self.parallel_games, 1)), onehot_code], axis=1)\n",
        "        self.state = tmpState\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import gym\n",
        "# from gym import spaces\n",
        "\n",
        "# idea don't penalize strictly on holding even when the price falls upto a certain level\n",
        "# use the idea of stoploss i.e when the price fall below stoploss start penalizing heavily for subsequent drops\n",
        "# create levels:\n",
        "\n",
        "# rise :\n",
        "# All values  :  MULTIPLIER = 0.9\n",
        "\n",
        "# fall :\n",
        "# [   > 1.5 )%  :  MULTIPLIER = 1.5\n",
        "# [1.5 - 0.5)%  :  MULTIPLIER = 1.0\n",
        "# [0.5 - 0)%    :  MULTIPLIER = 0.8\n",
        "# [0 -  0.5)%   :  MULTIPLIER = 0.2\n",
        "# [0.5  - 1)%   :  MULTIPLIER = 1.0\n",
        "# [1 -  1.5)%   :  MULTIPLIER = 2.0\n",
        "# [1.5 -  2)%   :  MULTIPLIER = 3.0\n",
        "# [ >=   2 )%   :  MULTIPLIER = 4.0\n",
        "# [ may force it to sell ] ?\n",
        "        # if self.actions[action] == \"LONG\":\n",
        "        #     if self.position == -1:\n",
        "        #         for b in self.boughts:\n",
        "        #             self.budget += -b\n",
        "        #             self.reward += -(b + 1)\n",
        "                \n",
        "        #         realized_pnl = self.reward\n",
        "        #         if self.cumulative_reward:\n",
        "        #             self.reward = self.reward / max(1, len(self.boughts))\n",
        "                \n",
        "        #         # if got bankrupt\n",
        "        #         if self.sudden_death * len(self.boughts) > self.reward:\n",
        "        #             self.nextDay = True\n",
        "\n",
        "        #         self.boughts = []\n",
        "        #         self.position = 0\n",
        "        #     elif self.budget > 0:\n",
        "        #         self.boughts.append(1.0)\n",
        "        #         self.position = 1\n",
        "        #         self.budget -= 1.\n",
        "        \n",
        "        # elif self.actions[action] == \"SHORT\":\n",
        "        #     if self.position == 1:\n",
        "        #         for b in self.boughts:\n",
        "        #             self.budget += b\n",
        "        #             self.reward += b - 1\n",
        "                \n",
        "        #         realized_pnl = self.reward\n",
        "        #         if self.cumulative_reward:\n",
        "        #             self.reward = self.reward / max(1, len(self.boughts))\n",
        "\n",
        "        #         if self.sudden_death * len(self.boughts) > self.reward:\n",
        "        #             self.nextDay = True\n",
        "\n",
        "        #         self.boughts = []\n",
        "        #         self.position = 0\n",
        "        #     elif self.budget > 0:\n",
        "        #         self.boughts.append(-1.0)\n",
        "        #         self.position = -1\n",
        "        #         self.budget -= 1.\n",
        "        \n",
        "        # else:\n",
        "        #     temp = temp * self.position\n",
        "        #     self.reward = self._get_holding_mutiplier(cum_reward, temp) * temp\n",
        "\n",
        "        # self.currentTargetIndex += 1\n",
        "    # def nextDay(self):\n",
        "    #     self.currentTargetIndex = self.scope - 1\n",
        "    #     self.currentDay = self.attack_sequence[self.day_index]\n",
        "    #     self.nextday = False\n",
        "    #     self.boughts = []\n",
        "    #     self.reward = 0.\n",
        "    #     self.position = 0\n",
        "    #     self.budget = self.budget*0 + 8.        # automation required # meaning power to buy x shares at current price\n",
        "    #     self._defineState()\n",
        "\n",
        "    #     return self.state\n",
        "\n",
        "        # tmpState['code'] = self.targetCode\n",
        "        # tmpState['day'] = self.currentDay\n",
        "        # tmpState['index'] = self.currentTargetIndex"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxfnNg8FJpUc"
      },
      "source": [
        "# parameters\n",
        "# epsilon = .5  # exploration\n",
        "# large_batches = True  # train in large batches for less I/O overhead.\n",
        "# min_epsilon = 0.1\n",
        "# batch_size = 16384 if large_batches else 64\n",
        "# discount = 0.9    # increasing future discount incentivise future P\n",
        "# epoch = 100\n",
        "# win_cnt = 0\n",
        "# train_cycle = 20000 if large_batches else 30\n",
        "# conter = 0\n",
        "\n",
        "# for e in range(epoch):\n",
        "#   loss = 0.\n",
        "#   day = 0\n",
        "#   game_over = False\n",
        "#   delay = True\n",
        "#   env.reset()\n",
        "\n",
        "#   while not game_over:\n",
        "    \n",
        "#     input_t = env.nextDay()\n",
        "#     day_end = False\n",
        "#     cumReward, realized_pnl, per_success, num_trades = 0, 0, 0, 0\n",
        "#     if delay and len(exp_replay.memory) > 40000:\n",
        "#       print('switching training delay off..')\n",
        "#       delay = False\n",
        "\n",
        "#     while not day_end:\n",
        "\n",
        "#       input_tm1 = input_t\n",
        "#       isRandom = False\n",
        "#       q = [None]\n",
        "\n",
        "#       # get next action\n",
        "#       if np.random.rand() <= epsilon or delay:\n",
        "#         action = np.random.randint(0, len(env.actions), size=1)[0]\n",
        "#         isRandom = True\n",
        "#       else:\n",
        "#         q = model_interface.predict(input_tm1)\n",
        "#         action = np.argmax(q[0])\n",
        "\n",
        "#       if np.nan in q:\n",
        "#         print(\"OCCUR NaN!!!\", str(counter), str(day), str(input_tm1['code']))\n",
        "#         # exit()\n",
        "\n",
        "#       # apply action, get rewards and new state\n",
        "#       input_t, reward, day_end, game_over, info, pnl, success = env.step(action)\n",
        "#       per_success += success > 0\n",
        "#       num_trades += abs(success)\n",
        "#       cumReward += reward\n",
        "#       realized_pnl += pnl\n",
        "\n",
        "#       # store experience\n",
        "#       exp_replay.remember([input_tm1,\n",
        "#                 action,\n",
        "#                 reward,\n",
        "#                 input_t],\n",
        "#                 day_end)\n",
        "\n",
        "#       # adapt model\n",
        "#       if counter % train_cycle == 0 and not delay:\n",
        "#         inputs, targets = exp_replay.get_offline_batch(env, model_interface, batch_size)\n",
        "#         if large_batches:\n",
        "#           loss = model_interface.fitModel(inputs, targets, 64, 10)\n",
        "#         else:\n",
        "#           loss = model_interface.batchTrain(inputs, targets)\n",
        "#         print('batch = ', str(counter // train_cycle), 'loss = ', str(loss))\n",
        "      \n",
        "#       counter += 1\n",
        "\n",
        "#     day += 1\n",
        "#     print('day = ', str(day), 'cumReward =', str(cumReward), 'pnl =', str(realized_pnl), 'percentage success', str(float(per_success) * 100 / max(num_trades, 1)))\n",
        "\n",
        "#     if cumReward > 0:\n",
        "#       win_cnt += 1\n",
        "    \n",
        "#     # kill this game randomly, expected 30 games in a row\n",
        "#     game_over = np.random.randint(30) == 0\n",
        "  \n",
        "#   print('switching game! epsilon=', str(epsilon))\n",
        "#   # print(\"Epoch {:03d}/{} | Loss {:.4f} | Win count {} | Epsilon {:.4f}\".format(e, epoch, loss, win_cnt, epsilon))\n",
        "#   # Save trained model weights and architecture, this will be used by the visualization code\n",
        "#   if day >= 800:\n",
        "#     epsilon = max(min_epsilon, epsilon * 0.99)\n",
        "#     model_interface.model.save_weights(\"model.h5\", overwrite=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}